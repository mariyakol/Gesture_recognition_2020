# Gesture_recognition_2020
Recognition system for a subset of static and dynamic gestures of the American sign language.
The primary objective of this work is to create a recognition system for a subset of static and dynamic gestures of the American sign language. To solve this problem, I proposed to use a model based on convolutional neural networks. The experimental results carried on two well-known datasets â€“ NCSLGR Corpus and WLASL. As a pre-processing step the input stream of the frames was converted into a color-coded optical flow. To implement all the methods and algorithms TensorFlow, Keras, OpenCV, scikit-learn libraries were used.

The result of the work is a program that recognizes a subset of the dynamic and static gestures of the American sign language. Recognition accuracy is 97%.
