# -*- coding: utf-8 -*-
"""NEW_Cross_Validation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SY8c3l-eLbMR9VC92OAhf6HeJ4F5tJQ2
"""

import os
from google.colab import drive
import numpy as np
from numpy import *
import tensorflow as tf
from tensorflow import keras
import cv2
import glob
from random import shuffle
from sklearn.model_selection import KFold, StratifiedKFold
from sklearn.model_selection import cross_validate

drive.mount('/content/drive')
dataPath  = "/content/drive/My Drive/dataset/Optical_flow_full"

os.listdir(dataPath)

class Frame(object):
  def __init__(self, path):
    self.path = path

    # Getting the gloss
    label_and_extension = self.path.split('-')[-1] # **** - CAR . png
    self.sign_name = label_and_extension.split('.')[0] # CAR

    # Getting the image
    self.image = cv2.imread(path)
    self.image = cv2.resize(self.image, (int(324 / 5), int(242 / 5)))

  def get_image(self):
    return self.image

  def get_sign_name(self):
    return self.sign_name  

  def __str__(self):
    return self.path + '\n' + self.sign_name + '\n' + str(self.image)

class Image_Dataset(object): #/content/drive/My Drive/dataset/Optical_flow_full/
  def __init__(self, path): 
    self.path = path
    self.all_signs = []
    self.sign_occurencies = {}
    self.sign_name_to_index = {}

    self.read_signs()

  def read_signs(self):
    index = 0 
    images_paths = glob.glob(self.path + '/*/*.png')

    for image_path in images_paths:
      sign = Frame(image_path)
      self.all_signs.append(sign)
      sign_name = sign.get_sign_name() 
      if sign_name in self.sign_occurencies:
        self.sign_occurencies[sign_name] += 1.0
      else:
        self.sign_occurencies[sign_name] = 1.0
        self.sign_name_to_index[sign_name] = index  
        index += 1

  def get_class_count(self): # 16 classes or 8 class
    return len(self.sign_occurencies)

  def shuffle(self):
    shuffle(self.all_signs)

  def get_images(self):
    images = []

    for sign in self.all_signs:
      images.append(sign.get_image())  

    return array(images)

  def get_image_labels(self):
    labels = []

    for sign in self.all_signs:
      labels.append(self.sign_name_to_index[sign.get_sign_name()])
    
    return array(labels)

from keras.metrics import top_k_categorical_accuracy

def top2(y_true, y_pred):
  return top_k_categorical_accuracy(y_true, y_pred, k=2);

def top3(y_true, y_pred):
  return top_k_categorical_accuracy(y_true, y_pred, k=3);

def top4(y_true, y_pred):
  return top_k_categorical_accuracy(y_true, y_pred, k=4);

def get_model(input_shape, num_classes):
  kernel_size=(3, 3)
  pool_size=(2, 2)

  model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(32, kernel_size, padding='same', activation='relu', input_shape=input_shape),
    tf.keras.layers.Conv2D(32, kernel_size, padding='same', activation='relu'),
    tf.keras.layers.Conv2D(32, kernel_size, padding='same', activation='relu'),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.MaxPooling2D(pool_size=pool_size),
    tf.keras.layers.Conv2D(64, kernel_size, padding='same', activation='relu'),
    tf.keras.layers.Conv2D(64, kernel_size, padding='same', activation='relu'),
    tf.keras.layers.Conv2D(64, kernel_size, padding='same', activation='relu'),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.MaxPooling2D(pool_size=pool_size),
    tf.keras.layers.Conv2D(128, kernel_size, padding='same', activation='relu'),
    tf.keras.layers.Conv2D(128, kernel_size, padding='same', activation='relu'),
    tf.keras.layers.Conv2D(128, kernel_size, padding='same', activation='relu'),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.MaxPooling2D(pool_size=pool_size),

    tf.keras.layers.Flatten(),
    tf.keras.layers.Dropout(0.25),
    tf.keras.layers.Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),
    tf.keras.layers.Dense(num_classes, activation='softmax', kernel_regularizer=tf.keras.regularizers.l2(0.01)),
  ])
  
  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy', top2, top3, top4])

  return model

import numpy as np
import matplotlib.pyplot as plt 
import os
import tensorflow as tf
from tensorflow import keras 
from sklearn.metrics import accuracy_score
from sklearn.model_selection import cross_val_score

# Path to google drive dataset
dataset_path = "/content/drive/My Drive/dataset/Optical_flow_full/"

dataset = Image_Dataset(dataset_path)
dataset.shuffle()

images = dataset.get_images()
print(images.shape)
labels = dataset.get_image_labels()
print(labels.shape)
numb_images, img_rows, img_cols, img_channels = images.shape 
input_shape = (img_rows, img_cols, img_channels)
print(input_shape)
num_classes = dataset.get_class_count()
print(num_classes)
model = get_model(input_shape, num_classes)

model.summary()

# model parameters
n_epochs = 30
batch_size = 10

kf = KFold(n_splits=10, random_state=1, shuffle=True)
#skf = StratifiedKFold(n_splits=10, random_state=1, shuffle=True)

for train_index, test_index in kf.split(labels):
  labels_train = labels[train_index]
  labels_test = labels[test_index]
  images_train = images[train_index]
  images_test = images[test_index]
  labels_train = keras.utils.to_categorical(labels_train, num_classes)
  labels_test = keras.utils.to_categorical(labels_test, num_classes)
  history = model.fit(images_train, labels_train, batch_size=batch_size, epochs=n_epochs, verbose=1)
  score = model.evaluate(images_test, labels_test, verbose=1)
  print('Test loss:', score[0])
  print('Test accuracy:', score[1])

avg_score = np.mean(score_array)
print(avg_score)

def get_model_for_scoring():
  input_shape=(48, 64, 3)
  num_classes=8
  kernel_size=(3, 3)
  pool_size=(2, 2)

  model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(32, kernel_size, padding='same', activation='relu', input_shape=input_shape),
    tf.keras.layers.Conv2D(32, kernel_size, padding='same', activation='relu'),
    tf.keras.layers.Conv2D(32, kernel_size, padding='same', activation='relu'),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.MaxPooling2D(pool_size=pool_size),
    tf.keras.layers.Conv2D(64, kernel_size, padding='same', activation='relu'),
    tf.keras.layers.Conv2D(64, kernel_size, padding='same', activation='relu'),
    tf.keras.layers.Conv2D(64, kernel_size, padding='same', activation='relu'),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.MaxPooling2D(pool_size=pool_size),
    tf.keras.layers.Conv2D(128, kernel_size, padding='same', activation='relu'),
    tf.keras.layers.Conv2D(128, kernel_size, padding='same', activation='relu'),
    tf.keras.layers.Conv2D(128, kernel_size, padding='same', activation='relu'),
    tf.keras.layers.BatchNormalization(),
    tf.keras.layers.MaxPooling2D(pool_size=pool_size),

    tf.keras.layers.Flatten(),
    tf.keras.layers.Dropout(0.25),
    tf.keras.layers.Dense(512, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),
    tf.keras.layers.Dense(num_classes, activation='softmax', kernel_regularizer=tf.keras.regularizers.l2(0.01)),
  ])
  
  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy', top2, top3, top4])

  return model

from keras.wrappers.scikit_learn import KerasClassifier
classifier = KerasClassifier(build_fn=get_model_for_scoring, epochs=30, batch_size=10, verbose=1)
cross_val_score(classifier, images, labels, scoring="accuracy", cv=kf)